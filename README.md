# ğŸ‘— Text-to-Fashion Image Generation with CLIP-Guided GAN

This project is a Text-to-Fashion Image Generation App built with a custom GAN model to generate realistic **fashion images** from **text prompts** using CLIP-guided supervision. It uses the [DressCodePromptSketch](https://huggingface.co/datasets/Abhi5ingh/Dresscodepromptsketch) dataset and improves generation quality using **CLIP loss**, **WGAN-GP**, and **Adaptive Instance Normalization (AdaIN)**.

---

## ğŸŒ Demo

![Screenshot 2025-04-08 160732](https://github.com/user-attachments/assets/365ac863-c223-4627-89bb-f1d1c347f9f7)

---

## ğŸš€ Features

### ğŸ§  AI Model

- âœ… Text-to-image generation using CLIP text embeddings  
- âœ… Residual Generator with AdaIN for text conditioning  
- âœ… Spectral Normalized Discriminator  
- âœ… CLIP loss for text-image alignment  
- âœ… Gradient Penalty with WGAN-GP  
- âœ… Visualization and checkpoint saving per epoch  
- âœ… Optimized for GPU training (Kaggle/Colab)  
- âœ… Output: 64Ã—64 images, upscaled to 256Ã—256 using Real-ESRGAN in the browser

### ğŸ–¼ï¸ UI & UX (React)

- Real-time image upscaling using canvas for enhanced display  
- Prompt suggestions and animated loading visuals  
- Toggle between original and enhanced images  
- Download option for generated images  
- Responsive and themed using custom CSS variables  

### ğŸ–¥ï¸ Backend (Flask)

- REST API with `/generate` endpoint  
- Accepts JSON prompt from frontend and returns the generated image  
- Handles inference and image conversion to PNG  
- CORS enabled for local frontend communication  

---

## ğŸ§  Model Architecture

- **Generator**  
  - Fully connected + AdaIN + ConvTranspose layers  
  - Input: CLIP text embedding â†’ Output: 64Ã—64 RGB image  

- **Discriminator**  
  - Spectral normalized CNN + Fully Connected layers  
  - Conditional on both image and text embedding  

- **CLIP Model**  
  - `openai/clip-vit-base-patch32` (via ğŸ¤— Transformers)  
  - Used for text embedding and CLIP loss  

---

## ğŸ“¦ Dataset

**Name**: [`Abhi5ingh/Dresscodepromptsketch`](https://huggingface.co/datasets/Abhi5ingh/Dresscodepromptsketch)  
**Contents**:
- `text`: Prompt describing the fashion item  
- `image`: Ground truth image  
- `sketch`: Optional sketch of the fashion item  

---

## ğŸ› ï¸ Model Setup

```bash
pip install torch torchvision datasets transformers
```

---

## ğŸ“„ Training Script Overview

```python
# Load CLIP model and processor
clip_model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32").to(device)
clip_processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")

# Load dataset
from datasets import load_dataset
ds = load_dataset("Abhi5ingh/Dresscodepromptsketch", split='train')

# Create DataLoader
dataset = FashionDataset(ds)
loader = DataLoader(dataset, batch_size=32, shuffle=True)

# Initialize Generator & Discriminator
generator = Generator(embedding_dim=512).to(device)
discriminator = Discriminator(embedding_dim=512).to(device)

# Train for 20 epochs
for epoch in range(epochs):
    ...
```

---

## ğŸ§ª Loss Functions

- **Discriminator Loss**: WGAN-GP + Hinge loss  
- **Generator Loss**: Adversarial + `Î» * CLIP loss`  
- **CLIP Loss**: Cosine similarity between image/text features  

---

## ğŸ“Š Outputs

- Checkpoints saved per epoch: `gan_outputs2/checkpoint_epoch_*.pth`  
- Image previews saved: `gan_outputs2/prompt_image_epoch_*.png`  
- Final models:
  ```
  generator_final.pth
  discriminator_final.pth
  ```

---

## ğŸ“· Sample Output 


---

## ğŸš€ Getting Started

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/your-username/fashion-gan.git
cd fashion-gan
```

### 2ï¸âƒ£ Backend Setup (Flask)

```bash
cd backend
pip install -r requirements.txt
```

Ensure `app.py` imports your model:

```python
from one import generator, clip_processor, clip_model, generate_from_prompt
```

Run the Flask server:

```bash
python app.py
```

Server runs at: `http://localhost:5000`

### 3ï¸âƒ£ Frontend Setup (React)

```bash
cd frontend
npm install
npm start
```

React app runs at: `http://localhost:3000`

---

## ğŸ§ª Sample Prompts

- `dress lilac pink`  
- `blue surplice jersey maxi dress`  
- `sheath dress gray cut-out dress`  
- `pink haley tee`  

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ one/          # contains generator, CLIP models, etc.
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/App.js
â”‚   â”œâ”€â”€ src/App.css
â”‚   â””â”€â”€ ...
â””â”€â”€ README.md
```

---

## ğŸ§  Future Improvements

- ğŸ”¼ Generate 128Ã—128 or 256Ã—256 images (Real-ESRGAN upscaling)  
- âš™ï¸ Add residual connections and attention in the Generator  
- ğŸ’¬ Implement a text-to-sketch-to-image pipeline  

---

## ğŸ‘¨â€ğŸ’» Author

Built by **Nikhil Krishan**
Contact:s.nikhilkrishnan@gmail.com

---
